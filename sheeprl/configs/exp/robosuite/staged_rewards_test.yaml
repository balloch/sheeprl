# @package _global_

defaults:
  - override /algo: sac
  - override /env: robosuite
  - override /model_manager: sac 
  - _self_

exp_name: sac_Panda_PickPlace_staged_rewards_test
root_dir: sac/staged_rewards/

algo:
  total_steps: 3_000_000
  learning_starts: 5_000 
  per_rank_batch_size: 128
  mlp_keys:
    encoder: [state, object-state]

buffer:
  size: 200_000
  checkpoint: False
  sample_next_obs: False

fabric:
  accelerator: cuda
  precision: bf16-mixed
  devices: [0, 1]

env:
  num_envs: 2
  wrapper:
    bddl_file: scenes/LIBERO_OBJECT_SCENE_pick_up_the_tomato_sauce_and_place_it_in_the_basket.bddl


metric:
  log_every: 1000
  sync_on_compute: False
  aggregator:
    metrics:
      Loss/value_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/policy_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/alpha_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Rewards/rew_avg_ep:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Rewards/rew_max_ep:
        _target_: torchmetrics.MaxMetric
        sync_on_compute: ${metric.sync_on_compute}
      Rewards/reach_avg_ep:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Rewards/reach_max_ep:
        _target_: torchmetrics.MaxMetric
        sync_on_compute: ${metric.sync_on_compute}
      Rewards/grasp_avg_ep:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Rewards/grasp_max_ep:
        _target_: torchmetrics.MaxMetric
        sync_on_compute: ${metric.sync_on_compute}
      Rewards/lift_avg_ep:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Rewards/lift_max_ep:
        _target_: torchmetrics.MaxMetric
        sync_on_compute: ${metric.sync_on_compute}
      Rewards/hover_avg_ep:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Rewards/hover_max_ep:
        _target_: torchmetrics.MaxMetric
        sync_on_compute: ${metric.sync_on_compute}