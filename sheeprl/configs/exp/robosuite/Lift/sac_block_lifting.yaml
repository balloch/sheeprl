# @package _global_

defaults:
  - override /algo: sac
  - override /env: robosuite
  - override /model_manager: sac
  - _self_

# Algorithm
algo:
  total_steps: 3000000
  learning_starts: 1000
  per_rank_batch_size: 128
  replay_ratio: 1
  mlp_keys:
    encoder: [state, object-state]

# Checkpoint
checkpoint:
  every: 50000

# Buffer
buffer:
  size: 1000000
  checkpoint: False
  sample_next_obs: False

env:
  num_envs: 1
  wrapper: 
    bddl_file: null
    env_name: Lift
    # For human observation
    use_camera_obs: True
    reward_shaping: True
    control_freq: 20

fabric:
  accelerator: cuda
  precision: bf16-mixed
  devices: 2


metric:
  aggregator:
    metrics:
      Loss/value_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/policy_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/alpha_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
      Loss/entropy_loss:
        _target_: torchmetrics.MeanMetric
        sync_on_compute: ${metric.sync_on_compute}
